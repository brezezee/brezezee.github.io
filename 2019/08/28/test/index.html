<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="../../../../lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="../../../../lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="../../../../css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="../../../../images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="../../../../images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="../../../../images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="../../../../images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="&amp;emsp;&amp;emsp;支持向量机是一种二分类模型，它以间隔最大作为优化目标，因此它比感知机仅仅以误分类推动的模型要优胜不少。数据线性可分时，SVM直接以间隔最大训练出一个线性分类模型。当数据线性不可分时，SVM通过软间隔最大化解决这种问题。此时的模型仍是一个线性模型，若采用核方法和软间隔最大化，则得到一个非线性模型。可以看到SVM在解决变复杂的情况时是逐步改进的。 1. 定义&amp;emsp;&amp;ems">
<meta name="keywords" content="ml,dl,cv,ai">
<meta property="og:type" content="article">
<meta property="og:title" content="SVMceshi">
<meta property="og:url" content="https://brezezee.github.io/2019/08/28/test/index.html">
<meta property="og:site_name" content="brezezee">
<meta property="og:description" content="&amp;emsp;&amp;emsp;支持向量机是一种二分类模型，它以间隔最大作为优化目标，因此它比感知机仅仅以误分类推动的模型要优胜不少。数据线性可分时，SVM直接以间隔最大训练出一个线性分类模型。当数据线性不可分时，SVM通过软间隔最大化解决这种问题。此时的模型仍是一个线性模型，若采用核方法和软间隔最大化，则得到一个非线性模型。可以看到SVM在解决变复杂的情况时是逐步改进的。 1. 定义&amp;emsp;&amp;ems">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://i.loli.net/2019/08/14/i2t9IzB1c7qQJVv.jpg">
<meta property="og:image" content="https://i.loli.net/2019/08/27/PyvipKD32dVbUHT.png">
<meta property="og:updated_time" content="2019-08-28T13:59:08.055Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SVMceshi">
<meta name="twitter:description" content="&amp;emsp;&amp;emsp;支持向量机是一种二分类模型，它以间隔最大作为优化目标，因此它比感知机仅仅以误分类推动的模型要优胜不少。数据线性可分时，SVM直接以间隔最大训练出一个线性分类模型。当数据线性不可分时，SVM通过软间隔最大化解决这种问题。此时的模型仍是一个线性模型，若采用核方法和软间隔最大化，则得到一个非线性模型。可以看到SVM在解决变复杂的情况时是逐步改进的。 1. 定义&amp;emsp;&amp;ems">
<meta name="twitter:image" content="https://i.loli.net/2019/08/14/i2t9IzB1c7qQJVv.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://brezezee.github.io/2019/08/28/test/">





  <title>SVMceshi | brezezee</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">brezezee</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="https://brezezee.github.io" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="https://brezezee.github.io/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="https://brezezee.github.io/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="https://brezezee.github.io/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="https://brezezee.github.io/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://brezezee.github.io">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="brezezee">
      <meta itemprop="description" content>
      <meta itemprop="image" content="../../../../images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="brezezee">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">SVMceshi</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-28T19:32:12+08:00">
                2019-08-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-08-28T21:59:08+08:00">
                2019-08-28
              </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/08/28/test/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.6k
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>&emsp;&emsp;支持向量机是一种二分类模型，它以间隔最大作为优化目标，因此它比感知机仅仅以误分类推动的模型要优胜不少。数据线性可分时，SVM直接以间隔最大训练出一个线性分类模型。当数据线性不可分时，SVM通过软间隔最大化解决这种问题。此时的模型仍是一个线性模型，若采用核方法和软间隔最大化，则得到一个非线性模型。可以看到SVM在解决变复杂的情况时是逐步改进的。</p>
<h2 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h2><p>&emsp;&emsp;前面已经学习过的线性分类有感知机和$Logistic$回归。感知机对误分类点进行优化，得到一个对训练样本的分类超平面，但这个超平面并不是最优的，而且只能用于数据线性可分的情况。而$Logistic$回归是一个对数线性模型，它将数据映射到0到1之间，对有较大差异的数据有较好适应性。通常，$Logistic$回归中的线性部分$w^Tx+b &gt; 0$时，该模型输出就大于0.5 这时输入$x$被分为$y=1$那一类。</p>
<p>&emsp;&emsp;上面已说到，SVM问题分三个阶段，一是线性可分、二是线性不可分但可放弃部分奇异点用线性分割、三是线性不可分且数据本身就非线性可分。解决这些问题都是一步一步来的，图1 是一个线性可分的SVM示意图，中间是得到的分类超平面，两端虚线是支持向量到超平面的最大间隔线。而这条线上的就是支持向量，支持向量到超平面的间隔是所有样本点中最近的。</p>
<center class="half">
<img src="https://i.loli.net/2019/08/14/i2t9IzB1c7qQJVv.jpg" width="600">
</center>


<p>&emsp;&emsp; 定义:线性可分支持向量机是给定数据集，通过最大间隔法确定的分离超平面</p>
<script type="math/tex; mode=display">
\boldsymbol{w^{\ast}\cdot x} + b^{\ast} = 0</script><p>和分类决策函数</p>
<script type="math/tex; mode=display">
y = sign(\boldsymbol{w^{\ast} \cdot x} + b^{\ast})</script><p>所定义的分类模型。其中sign是符号函数，当$\boldsymbol{w^{\ast}\cdot x} +b^{\ast} &gt; 0$时取 1 ，反之取0 。并且$|w^{\ast}x+b^{\ast}|$越大代表确信度越高。</p>
<h3 id="1-1-函数间隔和几何间隔"><a href="#1-1-函数间隔和几何间隔" class="headerlink" title="1.1 函数间隔和几何间隔"></a>1.1 函数间隔和几何间隔</h3><p>&emsp;&emsp;数据集中，一个点离超平面越远，那么确信其判断正确性的可能就越大，它可以由$\boldsymbol{w\cdot x}+b$来表示。若要建立一个即可判断确信度又能判断其分类正确性的函数，则需要引进一个符号变量，巧合的是$y\in\{-1,1\}$，并且若分类正确 $\boldsymbol{w\cdot x} +b$ 与$y$的符号是一致的。那么可由$y(\boldsymbol{w\cdot x} + b)$来表示分类的正确性和确信度，这就是函数间隔的意义。</p>
<p>&emsp;&emsp;对于给定样本集和超平面，超平面关于样本点$(\boldsymbol{x_i},y_i)$的函数间隔为</p>
<script type="math/tex; mode=display">
\widehat \gamma_i = y_i(\boldsymbol{w\cdot x_i} + b)</script><p>超平面关于数据集的函数间隔为</p>
<script type="math/tex; mode=display">
\widehat \gamma = \underset {i} {min} \;\widehat \gamma _i</script><p>事实上，超平面关于整个数据集的函数间隔就是超平面关于支持向量的函数间隔。显然，我们需要优化的便是这个关于支持向量的间隔，使它最大也就使得超平面对数据集中所有点都有较远距离。</p>
<p>&emsp;&emsp;但是直接对函数间隔最大化有个问题，函数间隔是关于参数$\boldsymbol{w},b$的函数，若$\boldsymbol{w},b$成比例的增加，这时超平面是 不会变 的，但是函数间隔会按相同比例增加。所以直接最大化函数间隔得到的结果肯定是无穷大了，因此需要对其进行规范化。这里对法向量 $w$ 进行标准化，标准化后的结果就是几何间隔.</p>
<script type="math/tex; mode=display">
\gamma_i = y_i\frac { \boldsymbol{w \cdot x_i} +b } {||\boldsymbol{w}||}</script><p>其中，$||\boldsymbol{w}||$ 是第二范式。</p>
<p>&emsp;&emsp;在二维情形下，$\boldsymbol{w}\cdot \boldsymbol{x} + b/ ||w||$就是点到直线的距离公式没加绝对值符号，标准化后的几何间隔就不会因$\boldsymbol{w},b$按比例放缩而产生变化。同样，超平面关于数据集的几何间隔为</p>
<script type="math/tex; mode=display">
\gamma = \underset i {min} \; \gamma_i</script><p>函数间隔与几何间隔只是相差一个标准化因子</p>
<script type="math/tex; mode=display">
\begin{aligned}
\gamma_i &= \frac {\widehat \gamma_i} {||\boldsymbol{w}||}\\
\gamma &= \frac {\widehat \gamma} {||\boldsymbol{w}||}
\end{aligned}</script><h3 id="1-2-间隔最大化"><a href="#1-2-间隔最大化" class="headerlink" title="1.2 间隔最大化"></a>1.2 间隔最大化</h3><p>&emsp;&emsp;定义了几何间隔后，就能通过最大化支持向量到超平面的几何间隔得到一个最优的分类超平面。在感知机中，学习的方法是最小化误差距离。这种方法只要超平面能够正确分类已知的数据，学习过程便结束。而对SVM中最大化几何间隔来说，当还未能正确分类所有样本点时，数据集中几何间隔最小的样本点是负的，此时的最大化过程是找到一个能够正确分割数据集的超平面。当几何间隔学习到大于0的时侯，超平面已能将数据集正确分割，但学习过程不会停止，SVM希望让最靠近超平面的样本点的分类结果仍有较大的确信度，这就是最大化几何间隔的目的。</p>
<p>&emsp;&emsp;现在导出其数学表达，目的是求解关于参数$\boldsymbol{w},b$的超平面，使超平面到数据集中几何间隔最小的的点关于它的几何间隔最大</p>
<script type="math/tex; mode=display">
arg \underset {w,b} {max}\;\underset {i} {min} \;\gamma_i \tag{1.2-a}</script><p>若对该式直接计算，难度非常大，因为$\gamma$ 的分子和分母都包含了变量$\boldsymbol{w},b$，因此先将其等价替换为函数间隔，问题变为</p>
<script type="math/tex; mode=display">
arg  \underset {w,b} {max}\;\underset {i} {min} \;\frac {\widehat \gamma_i}{||\boldsymbol{w}||} \tag{1.2-b}</script><p>因为$||\boldsymbol{w}||$与 $i$无关，可以直接将其提出来</p>
<script type="math/tex; mode=display">
arg  \underset {w,b} {max}\;\left \{  \frac {1}{||\boldsymbol{w}||}  \underset {i} {min} \; \widehat \gamma_i  \right \} \tag{1.2-c} \\</script><p>为了简化计算，需要利用函数间隔的性质：函数间隔的大小随$\boldsymbol{w},b$的放缩而放缩，对于同一组$\boldsymbol{w},b$ 所有样本的函数间隔的相对间隔也是按相同比例放缩。所以我们可以用函数间隔最小的点作为基准点，将其函数间隔令为1。那么其他点的函数间隔只是按$1/\gamma$的比例进行放缩，并不影响其相对超平面的位置，也不会影响超平面的位置。直接将其令为1后就不能这样写作一个式子了，需要将其他点函数间隔大于1的约束单独写出来，则问题变为解一个规划问题</p>
<script type="math/tex; mode=display">
\begin{aligned}
\underset {w,b} {max} \;\; &\frac {1} {||\boldsymbol{w}||}\\
\underset i {min} \;\;&\widehat \gamma_i \geqslant 1,\;\;\; i=1,2,\cdots, n
\end{aligned}</script><p>同样为了计算方便，将最大化$||\boldsymbol{w}||^{-1}$改为等价的最小化$||\boldsymbol{w}||^2$，于是问题变为二次规划问题</p>
<script type="math/tex; mode=display">
\begin{aligned}
\underset {w,b} {min} \;\; & \frac 1 2 {||\boldsymbol{w}||^2} \\
\underset i {min} \;\;&\widehat \gamma_i \geqslant 1,\;\;\; i=1,2,\cdots, n
\end{aligned}</script><p>&emsp;&emsp;其中$1/ 2$是为了简化计算结果。这就是SVM要解决的基本问题，下面讨论SVM如何解决这一问题，并且对于更复杂的情形如何处理。</p>
<h2 id="2-线性可分SVM"><a href="#2-线性可分SVM" class="headerlink" title="2. 线性可分SVM"></a>2. 线性可分SVM</h2><p>&emsp;&emsp;定义中导出的问题实际就是根据线性可分的情况推导的，因此我们只需要求解基本情况的二次规划问题就能得到一个线性可分的SVM模型。求解这类带约束优化问题的基本思路就是先通过拉格朗日函数转化为无约束优化问题。</p>
<script type="math/tex; mode=display">
L(w,b,\lambda) = \frac 1 2 ||\boldsymbol{w}||^2 +\sum_i^n \lambda_i -  \sum_i^n \lambda_i [y_i(\boldsymbol{\boldsymbol{w}\cdot x_i} + b) ]</script><p>注意$\boldsymbol{w},\; \boldsymbol{x_i}$是维度相同的 <strong>向量</strong> ，对于这个广义拉格朗日的最小化问题可以求偏导令为0，再利用KKT条件约束来解，但这样计算量太大。因为这个函数是凸函数，所以可以求解其对偶问题来得到原问题等价的解。关于对偶性在另一篇笔记——拉格朗日对偶性(Lagrange duality)</p>
<h3 id="2-1-对偶问题"><a href="#2-1-对偶问题" class="headerlink" title="2.1 对偶问题"></a>2.1 对偶问题</h3><p>&emsp;&emsp;首先写出原问题的极小极大形式</p>
<script type="math/tex; mode=display">
\underset {\boldsymbol{w},b}{min}\; L(\boldsymbol{w},b,\lambda) = \underset {w,b} {min}\; \underset {\lambda} {max} \;L(\boldsymbol{w},b,\lambda)</script><p>其对偶问题便是极大极小问题</p>
<script type="math/tex; mode=display">
\underset {\lambda} {max} \;\underset {w,b} {min}\; L(\boldsymbol{w},b,\lambda)</script><p>在原问题中，先求关于$\lambda$的极大，便会对$\lambda$求偏导得到一串等式，但这个结果实际上就是原来的约束条件。仍未简化问题，但若先对$\boldsymbol{w},b$先计算极小，则会得到一个较易计算的式子。这是使用对偶性的原因。</p>
<p>&emsp;&emsp;那么可以先求解内部的极小问题，对$\boldsymbol{w},b$求偏导并令为0得</p>
<script type="math/tex; mode=display">
\begin{aligned}
\triangledown _wL(\boldsymbol{w},b,\lambda) =\boldsymbol{w} - \sum_i^n \lambda_i y_i\boldsymbol{x_i}=0\\
\triangledown _bL(\boldsymbol{w},b,\lambda) =-\sum_i^n  \lambda_i y_i = 0
\end{aligned}</script><p>注意对$\boldsymbol{w}$的求导是对向量的求导，可查阅矩阵微分方面的内容。由上式得到</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{w} = \sum_i^n \lambda_i y_i\boldsymbol{x_i}\\
\sum_i^n  \lambda_i y_i = 0
\end{aligned}</script><p>带入原拉格朗日函数</p>
<script type="math/tex; mode=display">
\begin{aligned}
L(w,b,\lambda) =& \frac 1 2 \boldsymbol{w^Tw} +\sum_i^n \lambda_i - \sum_i^n \lambda_iy_i(\boldsymbol{\boldsymbol{w^T}\cdot x_i} + b)\\
=& \frac 1 2 \left( \sum_i^n\lambda_i y_i \boldsymbol{x_i} \right)^T \boldsymbol{\cdot} \left ( \sum_j^n \lambda_j y_j \boldsymbol{x_j} \right)+\sum_i^n \lambda_i - \sum_i^n \lambda_iy_i  \left (\left( \sum_j^n \lambda_j y_j \boldsymbol{x_j} \right)\cdot \boldsymbol{x_i}+b \right)\\
=& \frac 1 2\ \sum_i^n\lambda_i y_i \boldsymbol{x_i} ^T \boldsymbol{\cdot} \sum_j^n \lambda_j y_j \boldsymbol{x_j} +\sum_i^n \lambda_i - \sum_i^n \lambda_iy_i  \left (\left( \sum_j^n \lambda_j y_j \boldsymbol{x_j} \right)\cdot \boldsymbol{x_i}+b \right)\\
=& \frac 1 2 \sum_i^n\sum_j^n \lambda_i\lambda_jy_iy_j (\boldsymbol{x_i^T\cdot x_j})+\sum_i^n \lambda_i - \sum_i^n\sum_j^n \lambda_i\lambda_jy_iy_j (\boldsymbol{x_i^T\cdot x_j})-\sum_i^n\lambda_i y_ib\\
=&- \frac 1 2\sum_i^n\sum_j^n \lambda_i\lambda_jy_iy_j (\boldsymbol{x_i^T\cdot x_j}) + \sum_i^n \lambda_i
\end{aligned}</script><p>这个函数是对$\boldsymbol{w},b$求极小后的函数，那么现在它只与$\lambda$有关。这样我们就得到了对偶问题，对$\lambda$求极大</p>
<script type="math/tex; mode=display">
\begin{aligned}
 \underset \lambda {max} \;\; &- \frac 1 2 \sum_i^n\sum_j^n \lambda_i\lambda_jy_iy_j (\boldsymbol{x_i^T\cdot x_j}) + \sum_i^n \lambda_i\\
s.t.\;\;& \sum_i^n \lambda_i y_i = 0 \\
& \lambda_i \ge 0, \;\; i=1,\cdots,n
\end{aligned}</script><p>根据凸优化习惯，将极大化转化为极小化</p>
<script type="math/tex; mode=display">
\begin{aligned}
 \underset \lambda {min} \;\; & \frac 1 2 \sum_i^n\sum_j^n \lambda_i\lambda_jy_iy_j (\boldsymbol{x_i^T\cdot x_j}) - \sum_i^n \lambda_i\\
s.t.\;\;& \sum_i^n \lambda_i y_i = 0 \\
& \lambda_i \ge 0, \;\; i=1,\cdots,n
\end{aligned}</script><p>其中，只有$\lambda$是未知变量，当未知变量个数较少时，可以较轻松的算出来，比如李航书中给出一个$\lambda$数量为3的例题，可以直接将下面约束中的等式将其中一个变量带换掉，然后对两个未知变量求偏导。依据不等式约束判断是否符合，不符合则在边界取得极值，两个变量尝试边界也较简单，分别带入比较大小即可。可是该对偶问题的未知变量$\lambda$的数量与样本数成正比，机器学习中成千上万的样本量使得计算变得非常复杂，很多变量不能轻易消去，且带边界的时候有很多组合。于是下面介绍简化这个问题的优化算法——SMO。</p>
<h3 id="2-2-序列最小最优算法-SMO"><a href="#2-2-序列最小最优算法-SMO" class="headerlink" title="2.2 序列最小最优算法(SMO)"></a>2.2 序列最小最优算法(SMO)</h3><p>&emsp;&emsp;SMO算法由Microsoft Research的John C. Platt在1998年提出，并成为最快的二次规划优化算法，特别针对线性SVM和数据稀疏时性能更优。关于SMO最好的资料就是他本人写的《Sequential Minimal Optimization A Fast Algorithm for Training Support Vector Machines》。</p>
<h4 id="2-2-1-坐标下降法"><a href="#2-2-1-坐标下降法" class="headerlink" title="2.2.1 坐标下降法"></a>2.2.1 坐标下降法</h4><p>&emsp;&emsp;SMO算法的思想与坐标下降法十分类似，因此先介绍下坐标下降法。它是一种非梯度优化算法，梯度优化算法是每次选择梯度最大的方向进行优化，当然这使得每次优化的程度较大。不过计算量较多，尤其是变量较多的情况。而坐标下降法每次只对一个坐标方向进行优化，如此循环，对每个坐标轴依次优化。这样的做法可能会使得优化过程显得较为曲折，不过中间每步对单个坐标轴的计算比整个梯度的计算小得多。可以由下图表示</p>
<center class="half">
<img src="https://i.loli.net/2019/08/27/PyvipKD32dVbUHT.png" width="600">
</center>

<p>&emsp;&emsp;坐标下降法不一定是对坐标方向进行优化，也可以自己选择一组基，对这组基的方向进行优化。不过它的优化方向仍是在一开始就决定了。SMO也是这种思想，在SVM的对偶问题中，其对偶变量为$\boldsymbol{\lambda}$，而$\boldsymbol{\lambda}$的数量与样本的数量成正比。对如此多的变量同时优化无疑是比较困难的，因此借鉴坐标下降法，对其中一部分变量进行优化，不断循环的对所有变量依次优化，这样迭代可以得到一个期望的优化结果。</p>
<p>对于SVM的对偶问题:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\underset \lambda {min} \;\; & \frac 1 2 \sum_i^n\sum_j^n \lambda_i\lambda_jy_iy_j (\boldsymbol{x_i^T\cdot x_j}) - \sum_i^n \lambda_i\\
s.t.\;\;& \sum_i^n \lambda_i y_i = 0 \\
& \lambda_i \ge 0, \;\; i=1,\cdots,n
\end{aligned}</script><p>由于$\boldsymbol\lambda$数量等于样本$(\boldsymbol{x_i},y_i)$数量，使得这个二次规划问题计算量较大，因此选择其中两个作为变量，其他看做常数，对这两个变量解二次规划问题，并且这时两个变量满足约束$\sum_i^n \lambda_i y_i = 0$ ，所以这个问题有解析解，求解速度非常快。</p>
<p>那么为什么选两个变量呢？</p>
<p>&emsp;&emsp;同样是因为约束条件$\sum_i^n \lambda_i y_i = 0$ ，$\lambda_i$在更新后需要满足它们之间的等式，所以需要同时更新两个变量。</p>
<h4 id="2-2-2-SMO求解方法"><a href="#2-2-2-SMO求解方法" class="headerlink" title="2.2.2 SMO求解方法"></a>2.2.2 SMO求解方法</h4><h2 id="3-线性不可分SVM"><a href="#3-线性不可分SVM" class="headerlink" title="3. 线性不可分SVM"></a>3. 线性不可分SVM</h2><h3 id="3-1-松弛变量"><a href="#3-1-松弛变量" class="headerlink" title="3.1 松弛变量"></a>3.1 松弛变量</h3><h3 id="3-2-求解对偶问题"><a href="#3-2-求解对偶问题" class="headerlink" title="3.2 求解对偶问题"></a>3.2 求解对偶问题</h3><h3 id="3-3-支持向量机求解参数-w-b"><a href="#3-3-支持向量机求解参数-w-b" class="headerlink" title="3.3 支持向量机求解参数$w,b$"></a>3.3 支持向量机求解参数$w,b$</h3><h2 id="4-非线性SVM"><a href="#4-非线性SVM" class="headerlink" title="4. 非线性SVM"></a>4. 非线性SVM</h2><h2 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h2>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="../../27/剑指offer/" rel="next" title="剑指offer">
                <i class="fa fa-chevron-left"></i> 剑指offer
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">brezezee</p>
              <p class="site-description motion-element" itemprop="description">A learning notes blog</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="https://brezezee.github.io/archives">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="../../../../categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="../../../../tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-定义"><span class="nav-text">1. 定义</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-函数间隔和几何间隔"><span class="nav-text">1.1 函数间隔和几何间隔</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-间隔最大化"><span class="nav-text">1.2 间隔最大化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-线性可分SVM"><span class="nav-text">2. 线性可分SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-对偶问题"><span class="nav-text">2.1 对偶问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-序列最小最优算法-SMO"><span class="nav-text">2.2 序列最小最优算法(SMO)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-坐标下降法"><span class="nav-text">2.2.1 坐标下降法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-SMO求解方法"><span class="nav-text">2.2.2 SMO求解方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-线性不可分SVM"><span class="nav-text">3. 线性不可分SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-松弛变量"><span class="nav-text">3.1 松弛变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-求解对偶问题"><span class="nav-text">3.2 求解对偶问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-支持向量机求解参数-w-b"><span class="nav-text">3.3 支持向量机求解参数$w,b$</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-非线性SVM"><span class="nav-text">4. 非线性SVM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Reference"><span class="nav-text">5. Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">brezezee</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">50.4k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="../../../../lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="../../../../lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="../../../../lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="../../../../lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="../../../../lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="../../../../lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="../../../../lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="../../../../js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="../../../../js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="../../../../js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="../../../../js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="../../../../js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://brezezee.github.io/2019/08/28/test/';
          this.page.identifier = '2019/08/28/test/';
          this.page.title = 'SVMceshi';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
